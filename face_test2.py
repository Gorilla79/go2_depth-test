import face_recognition
import cv2
import numpy as np
import time

# ðŸ“· ì¹´ë©”ë¼ ì„¤ì •
video_capture = cv2.VideoCapture(0)

# âœ… ì¹´ë©”ë¼ ì„±ëŠ¥ í–¥ìƒ: ìžë™ ë…¸ì¶œ ë¹„í™œì„±í™” + ë°ê¸° ì¡°ì •
video_capture.set(cv2.CAP_PROP_BRIGHTNESS, 0.5)
video_capture.set(cv2.CAP_PROP_CONTRAST, 0.5)
video_capture.set(cv2.CAP_PROP_SATURATION, 0.6)
video_capture.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)  # ìˆ˜ë™ ë…¸ì¶œ ì„¤ì •
video_capture.set(cv2.CAP_PROP_EXPOSURE, -6)  # ì ì ˆí•œ ê°’ ì„¤ì • í•„ìš”

# ðŸ”¹ ìƒ˜í”Œ ì–¼êµ´ ë¡œë“œ (ì–¼êµ´ì´ ì—†ì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬)
def load_face_encoding(image_path):
    try:
        image = face_recognition.load_image_file(image_path)
        face_locations = face_recognition.face_locations(image, model="cnn")  # CNN ëª¨ë¸ë¡œ ë” ì •í™•í•œ ê°ì§€
        if len(face_locations) == 0:
            print(f"âŒ Warning: No face found in {image_path}")
            return None

        # âœ… ì¸ì½”ë”© í’ˆì§ˆ í–¥ìƒ: num_jitters=10 (ë” ë§Žì€ íŠ¹ì§• ì¶”ì¶œ)
        encodings = face_recognition.face_encodings(image, known_face_locations=face_locations, num_jitters=10)
        return encodings[0] if encodings else None
    except Exception as e:
        print(f"âŒ Error loading {image_path}: {e}")
        return None

# âœ… ë“±ë¡ëœ ì–¼êµ´ ë¡œë“œ
member1_face_encoding = load_face_encoding("member1.jpg")

# âœ… ìœ íš¨í•œ ì–¼êµ´ ì¸ì½”ë”©ë§Œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
known_face_encodings = []
known_face_names = []

if member1_face_encoding is not None:
    known_face_encodings.append(member1_face_encoding)
    known_face_names.append("Dongsup")

# ðŸŽï¸ ìµœì í™”ëœ ë³€ìˆ˜
face_locations = []
face_encodings = []
face_names = []
frame_count = 0

while True:
    ret, frame = video_capture.read()
    if not ret:
        continue

    # âœ… ì„±ëŠ¥ ìµœì í™”: 3í”„ë ˆìž„ë§ˆë‹¤ í•œ ë²ˆì”© ì–¼êµ´ ê°ì§€ ìˆ˜í–‰ (ê¸°ì¡´ 2 â†’ 3)
    frame_count += 1
    if frame_count % 3 == 0:
        continue

    # ðŸ”¹ BGR â†’ RGB ë³€í™˜
    rgb_frame = frame[:, :, ::-1]

    # âœ… í•´ìƒë„ ì¤„ì´ê¸° (ì†ë„ ìµœì í™”)
    small_frame = cv2.resize(rgb_frame, (0, 0), fx=0.5, fy=0.5)

    # ðŸ”¹ ì–¼êµ´ ê²€ì¶œ (ë” ì •í™•í•œ `cnn` ì‚¬ìš©)
    face_locations = face_recognition.face_locations(small_frame, model="hog")
    face_encodings = face_recognition.face_encodings(small_frame, face_locations)

    face_names = []
    for face_encoding in face_encodings:
        # âœ… ê°œì„ ëœ ì–¼êµ´ ë§¤ì¹­: ë” ë‚®ì€ `tolerance=0.5` + ê±°ë¦¬ ê¸°ë°˜ ë§¤ì¹­
        matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.5)
        name = "Unknown"

        if len(known_face_encodings) > 0:
            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
            best_match_index = np.argmin(face_distances)

            if matches[best_match_index] and face_distances[best_match_index] < 0.45:
                name = known_face_names[best_match_index]

        face_names.append(name)

    # ðŸ”¹ ì›ëž˜ í•´ìƒë„ë¡œ ë³€í™˜
    for (top, right, bottom, left), name in zip(face_locations, face_names):
        top *= 2
        right *= 2
        bottom *= 2
        left *= 2

        # âœ… ì–¼êµ´ ê°ì§€ ê²°ê³¼ í‘œì‹œ (ë” ì„ ëª…í•˜ê²Œ)
        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)
        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)
        font = cv2.FONT_HERSHEY_DUPLEX
        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)

    # ê²°ê³¼ í™”ë©´ ì¶œë ¥
    cv2.imshow('Face Recognition', frame)

    # ì¢…ë£Œ í‚¤ ('q')
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

video_capture.release()
cv2.destroyAllWindows()
